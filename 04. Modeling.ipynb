{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "#import required modules from scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, plot_confusion_matrix,precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#import algorithms modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "libdir = os.chdir(r'C:\\Users\\Nidhi\\Desktop\\Saransh\\FraudDetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>type_CASH_IN</th>\n",
       "      <th>type_CASH_OUT</th>\n",
       "      <th>type_DEBIT</th>\n",
       "      <th>type_PAYMENT</th>\n",
       "      <th>type_TRANSFER</th>\n",
       "      <th>isFlaggedFraud_0</th>\n",
       "      <th>isFlaggedFraud_1</th>\n",
       "      <th>CustTypeOrig_Customer</th>\n",
       "      <th>CustTypeDest_Customer</th>\n",
       "      <th>CustTypeDest_Merchant</th>\n",
       "      <th>Day_1.0</th>\n",
       "      <th>Day_10.0</th>\n",
       "      <th>Day_11.0</th>\n",
       "      <th>Day_12.0</th>\n",
       "      <th>Day_13.0</th>\n",
       "      <th>Day_14.0</th>\n",
       "      <th>Day_15.0</th>\n",
       "      <th>Day_16.0</th>\n",
       "      <th>Day_17.0</th>\n",
       "      <th>Day_18.0</th>\n",
       "      <th>Day_19.0</th>\n",
       "      <th>Day_2.0</th>\n",
       "      <th>Day_20.0</th>\n",
       "      <th>Day_21.0</th>\n",
       "      <th>Day_22.0</th>\n",
       "      <th>Day_23.0</th>\n",
       "      <th>Day_24.0</th>\n",
       "      <th>Day_25.0</th>\n",
       "      <th>Day_26.0</th>\n",
       "      <th>Day_27.0</th>\n",
       "      <th>Day_28.0</th>\n",
       "      <th>Day_29.0</th>\n",
       "      <th>Day_3.0</th>\n",
       "      <th>Day_30.0</th>\n",
       "      <th>Day_31.0</th>\n",
       "      <th>Day_32.0</th>\n",
       "      <th>Day_4.0</th>\n",
       "      <th>Day_5.0</th>\n",
       "      <th>Day_6.0</th>\n",
       "      <th>Day_7.0</th>\n",
       "      <th>Day_8.0</th>\n",
       "      <th>Day_9.0</th>\n",
       "      <th>Hour_0</th>\n",
       "      <th>Hour_1</th>\n",
       "      <th>Hour_2</th>\n",
       "      <th>Hour_3</th>\n",
       "      <th>Hour_4</th>\n",
       "      <th>Hour_5</th>\n",
       "      <th>Hour_6</th>\n",
       "      <th>Hour_7</th>\n",
       "      <th>Hour_8</th>\n",
       "      <th>Hour_9</th>\n",
       "      <th>Hour_10</th>\n",
       "      <th>Hour_11</th>\n",
       "      <th>Hour_12</th>\n",
       "      <th>Hour_13</th>\n",
       "      <th>Hour_14</th>\n",
       "      <th>Hour_15</th>\n",
       "      <th>Hour_16</th>\n",
       "      <th>Hour_17</th>\n",
       "      <th>Hour_18</th>\n",
       "      <th>Hour_19</th>\n",
       "      <th>Hour_20</th>\n",
       "      <th>Hour_21</th>\n",
       "      <th>Hour_22</th>\n",
       "      <th>Hour_23</th>\n",
       "      <th>transferAmntCheck_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.00</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.00</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181.00</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181.00</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.00</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7817.71</td>\n",
       "      <td>53860.00</td>\n",
       "      <td>46042.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7107.77</td>\n",
       "      <td>183195.00</td>\n",
       "      <td>176087.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7861.64</td>\n",
       "      <td>176087.23</td>\n",
       "      <td>168225.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4024.36</td>\n",
       "      <td>2671.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5337.77</td>\n",
       "      <td>41720.00</td>\n",
       "      <td>36382.23</td>\n",
       "      <td>41898.0</td>\n",
       "      <td>40348.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  newbalanceDest  \\\n",
       "0   9839.64      170136.00       160296.36             0.0            0.00   \n",
       "1   1864.28       21249.00        19384.72             0.0            0.00   \n",
       "2    181.00         181.00            0.00             0.0            0.00   \n",
       "3    181.00         181.00            0.00         21182.0            0.00   \n",
       "4  11668.14       41554.00        29885.86             0.0            0.00   \n",
       "5   7817.71       53860.00        46042.29             0.0            0.00   \n",
       "6   7107.77      183195.00       176087.23             0.0            0.00   \n",
       "7   7861.64      176087.23       168225.59             0.0            0.00   \n",
       "8   4024.36        2671.00            0.00             0.0            0.00   \n",
       "9   5337.77       41720.00        36382.23         41898.0        40348.79   \n",
       "\n",
       "   isFraud  type_CASH_IN  type_CASH_OUT  type_DEBIT  type_PAYMENT  \\\n",
       "0        0             0              0           0             1   \n",
       "1        0             0              0           0             1   \n",
       "2        1             0              0           0             0   \n",
       "3        1             0              1           0             0   \n",
       "4        0             0              0           0             1   \n",
       "5        0             0              0           0             1   \n",
       "6        0             0              0           0             1   \n",
       "7        0             0              0           0             1   \n",
       "8        0             0              0           0             1   \n",
       "9        0             0              0           1             0   \n",
       "\n",
       "   type_TRANSFER  isFlaggedFraud_0  isFlaggedFraud_1  CustTypeOrig_Customer  \\\n",
       "0              0                 1                 0                      1   \n",
       "1              0                 1                 0                      1   \n",
       "2              1                 1                 0                      1   \n",
       "3              0                 1                 0                      1   \n",
       "4              0                 1                 0                      1   \n",
       "5              0                 1                 0                      1   \n",
       "6              0                 1                 0                      1   \n",
       "7              0                 1                 0                      1   \n",
       "8              0                 1                 0                      1   \n",
       "9              0                 1                 0                      1   \n",
       "\n",
       "   CustTypeDest_Customer  CustTypeDest_Merchant  Day_1.0  Day_10.0  Day_11.0  \\\n",
       "0                      0                      1        1         0         0   \n",
       "1                      0                      1        1         0         0   \n",
       "2                      1                      0        1         0         0   \n",
       "3                      1                      0        1         0         0   \n",
       "4                      0                      1        1         0         0   \n",
       "5                      0                      1        1         0         0   \n",
       "6                      0                      1        1         0         0   \n",
       "7                      0                      1        1         0         0   \n",
       "8                      0                      1        1         0         0   \n",
       "9                      1                      0        1         0         0   \n",
       "\n",
       "   Day_12.0  Day_13.0  Day_14.0  Day_15.0  Day_16.0  Day_17.0  Day_18.0  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "2         0         0         0         0         0         0         0   \n",
       "3         0         0         0         0         0         0         0   \n",
       "4         0         0         0         0         0         0         0   \n",
       "5         0         0         0         0         0         0         0   \n",
       "6         0         0         0         0         0         0         0   \n",
       "7         0         0         0         0         0         0         0   \n",
       "8         0         0         0         0         0         0         0   \n",
       "9         0         0         0         0         0         0         0   \n",
       "\n",
       "   Day_19.0  Day_2.0  Day_20.0  Day_21.0  Day_22.0  Day_23.0  Day_24.0  \\\n",
       "0         0        0         0         0         0         0         0   \n",
       "1         0        0         0         0         0         0         0   \n",
       "2         0        0         0         0         0         0         0   \n",
       "3         0        0         0         0         0         0         0   \n",
       "4         0        0         0         0         0         0         0   \n",
       "5         0        0         0         0         0         0         0   \n",
       "6         0        0         0         0         0         0         0   \n",
       "7         0        0         0         0         0         0         0   \n",
       "8         0        0         0         0         0         0         0   \n",
       "9         0        0         0         0         0         0         0   \n",
       "\n",
       "   Day_25.0  Day_26.0  Day_27.0  Day_28.0  Day_29.0  Day_3.0  Day_30.0  \\\n",
       "0         0         0         0         0         0        0         0   \n",
       "1         0         0         0         0         0        0         0   \n",
       "2         0         0         0         0         0        0         0   \n",
       "3         0         0         0         0         0        0         0   \n",
       "4         0         0         0         0         0        0         0   \n",
       "5         0         0         0         0         0        0         0   \n",
       "6         0         0         0         0         0        0         0   \n",
       "7         0         0         0         0         0        0         0   \n",
       "8         0         0         0         0         0        0         0   \n",
       "9         0         0         0         0         0        0         0   \n",
       "\n",
       "   Day_31.0  Day_32.0  Day_4.0  Day_5.0  Day_6.0  Day_7.0  Day_8.0  Day_9.0  \\\n",
       "0         0         0        0        0        0        0        0        0   \n",
       "1         0         0        0        0        0        0        0        0   \n",
       "2         0         0        0        0        0        0        0        0   \n",
       "3         0         0        0        0        0        0        0        0   \n",
       "4         0         0        0        0        0        0        0        0   \n",
       "5         0         0        0        0        0        0        0        0   \n",
       "6         0         0        0        0        0        0        0        0   \n",
       "7         0         0        0        0        0        0        0        0   \n",
       "8         0         0        0        0        0        0        0        0   \n",
       "9         0         0        0        0        0        0        0        0   \n",
       "\n",
       "   Hour_0  Hour_1  Hour_2  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  \\\n",
       "0       0       1       0       0       0       0       0       0       0   \n",
       "1       0       1       0       0       0       0       0       0       0   \n",
       "2       0       1       0       0       0       0       0       0       0   \n",
       "3       0       1       0       0       0       0       0       0       0   \n",
       "4       0       1       0       0       0       0       0       0       0   \n",
       "5       0       1       0       0       0       0       0       0       0   \n",
       "6       0       1       0       0       0       0       0       0       0   \n",
       "7       0       1       0       0       0       0       0       0       0   \n",
       "8       0       1       0       0       0       0       0       0       0   \n",
       "9       0       1       0       0       0       0       0       0       0   \n",
       "\n",
       "   Hour_9  Hour_10  Hour_11  Hour_12  Hour_13  Hour_14  Hour_15  Hour_16  \\\n",
       "0       0        0        0        0        0        0        0        0   \n",
       "1       0        0        0        0        0        0        0        0   \n",
       "2       0        0        0        0        0        0        0        0   \n",
       "3       0        0        0        0        0        0        0        0   \n",
       "4       0        0        0        0        0        0        0        0   \n",
       "5       0        0        0        0        0        0        0        0   \n",
       "6       0        0        0        0        0        0        0        0   \n",
       "7       0        0        0        0        0        0        0        0   \n",
       "8       0        0        0        0        0        0        0        0   \n",
       "9       0        0        0        0        0        0        0        0   \n",
       "\n",
       "   Hour_17  Hour_18  Hour_19  Hour_20  Hour_21  Hour_22  Hour_23  \\\n",
       "0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0   \n",
       "5        0        0        0        0        0        0        0   \n",
       "6        0        0        0        0        0        0        0   \n",
       "7        0        0        0        0        0        0        0   \n",
       "8        0        0        0        0        0        0        0   \n",
       "9        0        0        0        0        0        0        0   \n",
       "\n",
       "   transferAmntCheck_1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "5                    1  \n",
       "6                    1  \n",
       "7                    1  \n",
       "8                    1  \n",
       "9                    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r'./data/interim/preprocessed.csv'\n",
    "df = pd.read_csv(file,nrows = 750000)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is: (750000, 73)\n"
     ]
    }
   ],
   "source": [
    "print('Dataset shape is:',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of independent dataset X is: (750000, 72)\n",
      "The shape of dependent/predicting dataset y is: (750000,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset into X and y to further feed into the model(s)\n",
    "\n",
    "X = df.drop('isFraud', axis = 1)\n",
    "y = df.isFraud\n",
    "\n",
    "print('The shape of independent dataset X is:',X.shape)\n",
    "print('The shape of dependent/predicting dataset y is:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue><b>Due to the highly imbalanced nature of the dataset, it is imperative to handle the imbalanceness otherwise this may cause inaccurate results resulting in models with high accuracy scores but actually not performing well.</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    749566\n",
       "1       434\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nidhi\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Approach\n",
    "- Splitting of data into train,test\n",
    "- Handling imbalance on training datasets using SMOTE\n",
    "- Standardization of training and test X datasets\n",
    "- Logistic Regression\n",
    "    - GridSearch\n",
    "    - Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'><b>\n",
    "There are multilpe models that will be fitted to see which model suits best\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "    </font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the datasets into train and test in ratio of 25% of test data and 75% for training the model(s)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this block is not run as oversampling is leading to overfitting of results; .99 precision and recall\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print('Prior to resampling:',counter)\n",
    "\n",
    "sm = SMOTE()\n",
    "X_train_sm,y_train_sm = sm.fit_resample(X_train,y_train)\n",
    "\n",
    "counter = Counter(y_train_sm)\n",
    "print('After resampling:',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "X_train_scl = s.fit_transform(X_train)\n",
    "X_test_scl = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed the data is highliy imbalanced, hence this problem should be handled prior to proceeding with training the model.<br><br>\n",
    "I have used SMOTE approach for oversampling the data points which results into synthetically generated data points resembling data points where isFraud=1 \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the oversample datasets both trainig and test are Standardized i.e. mean = 0 and std dev = 1 for all features in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Hyperparameter for tuning the model and getting best parameter for the model\n",
    "c = np.logspace(-3,3,10)\n",
    "param = {'C':c}\n",
    "#penalize = ['l1','l2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Grid Search with 5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')\n",
    "clf  = GridSearchCV(model,param, cv = 5,scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(class_weight='balanced'),\n",
       "             param_grid={'C': array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03])},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model\n",
    "clf.fit(X_train_scl,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.971937574284202\n",
      "Best Parameters: dict_values([1000.0])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\" + str(clf.best_score_))\n",
    "print(\"Best Parameters: \" + str(clf.best_params_.values()))\n",
    "best_c = clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected model with best ROC AUC score having 'C': 2.78, 'penalty': 'l2'\n",
    "\n",
    "model = LogisticRegression(C= best_c,class_weight = 'balanced')\n",
    "model.fit(X_train_scl,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176053,  11356],\n",
       "       [     5,     86]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x240a8572370>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model,X_test_scl,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for the model: 0.0075161685020101385\n",
      "Recall score for the model: 0.945054945054945\n"
     ]
    }
   ],
   "source": [
    "print('Precision Score for the model:', precision_score(y_test,y_pred))\n",
    "print('Recall score for the model:',recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Custom Hyperparameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "for c_num in c:\n",
    "    model = LogisticRegression(class_weight = 'balanced', C = c_num)\n",
    "    try:\n",
    "        model.fit(X_train_scl,y_train)\n",
    "        y_pred = model.predict(X_test_scl)\n",
    "        results.append([c_num,roc_auc_score(y_test,y_pred),precision_score(y_test,y_pred),recall_score(y_test,y_pred)])\n",
    "        \n",
    "    except:\n",
    "        print('Model cannot run for',c_num)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.872629</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.879121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.901099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.920822</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.912088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.935007</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.464159</td>\n",
       "      <td>0.936311</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.154435</td>\n",
       "      <td>0.936042</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.942163</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46.415888</td>\n",
       "      <td>0.942211</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>215.443469</td>\n",
       "      <td>0.942222</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.942230</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.945055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             C   ROC_AUC  Precision    Recall\n",
       "0     0.001000  0.872629   0.003179  0.879121\n",
       "1     0.004642  0.907731   0.005083  0.901099\n",
       "2     0.021544  0.920822   0.006248  0.912088\n",
       "3     0.100000  0.935007   0.007031  0.934066\n",
       "4     0.464159  0.936311   0.007328  0.934066\n",
       "5     2.154435  0.936042   0.007264  0.934066\n",
       "6    10.000000  0.942163   0.007500  0.945055\n",
       "7    46.415888  0.942211   0.007512  0.945055\n",
       "8   215.443469  0.942222   0.007514  0.945055\n",
       "9  1000.000000  0.942230   0.007516  0.945055"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(results,columns = ['C','ROC_AUC','Precision','Recall'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsOklEQVR4nO3deXwV9b3/8deHAGHfd0gI+yqCBFBbq4JWtFrUWhdcWitSbHHporfX23uv97a95Xa5rSgVEVGp4K6ttVa0KAIuQICwihIChACyQwIhIcvn98cZ+juNhxAgk3OSvJ+PRx6cmfnOmc8MJ+ed78z3zDF3R0REpLx68S5AREQSkwJCRERiUkCIiEhMCggREYlJASEiIjEpIEREJCYFhEg5Znazmb1diXbTzezfq6OmsJnZt81scdS0m1nveNYk8aeAkBrFzLaY2VEzO2xmu8zsKTNrVpXbcPc57v7VSrSb5O4/q8ptA5jZQ2ZWHOzjQTP70MzOq+rtiJyMAkJqoqvcvRlwDjAC+Gn5BmZWv9qrqlovBPvYDngPeCnO9UgdpICQGsvdtwN/AwbDP06LfN/MNgIbg3lXmllm1F/iQ46vb2YpZvaqme0xs31m9mgw/x+nWyzid2a228wOmdlqMzu+vafN7OdRz3enmWWZ2X4ze93MukQtczObZGYbzeyAmU0zM6vEPpYAc4CuZtY+eK6WZvakme00s+1m9nMzSypXxydmlm9m683snGD+T8xsU9T8a0774EudoICQGsvMUoArgJVRs68GRgEDgzfGWcB3gbbA48DrZpYcvKG+AWwF0oCuwPMxNvNV4CtAX6AVcAOwL0Yto4FfAtcDnYPnLf98VxLp8ZwdtLusEvvYELgt2OaBYPYzQAnQGxgW1DghaP9N4KFgnRbA16Pq3QRcALQE/gt41sw6n6wGqbsUEFIT/cnMDgKLgfeB/4la9kt33+/uR4E7gcfdfYm7l7r7M0ARcC4wEugC3O/uR9y90N0X80XFQHOgP2Du/om774zR7mZglruvcPci4F+B88wsLarNFHc/6O45RE4bDa1gH68P9vH4flzn7iVm1hG4HLgvqHs38DvgxmC9CcCv3H2ZR2S5+1YAd3/J3Xe4e5m7v0CklzWyghqkjlNASE10tbu3cvfu7v69IAyO2xb1uDvwo+D00sHgDTeFSDCkAFuDUzgn5O7vAo8C04BdZjbDzFrEaNqFSK/h+HqHifzl3jWqzedRjwuAii6uv+jurYCOwFpgeNQ+NQB2Ru3T40CHYHkKkZ7CF5jZbVGn2w4SOTXXroIapI5TQEhtE3174m3AL4IwOf7TxN2fC5alVuZitrtPdffhwCAip5ruj9FsB5E3bwDMrCmR01rbz2BfcPe9RE6RPRScDtpGpBfULmqfWrj7oGCVbUCv8s9jZt2BJ4DJQNsgfNYCJ70OInWXAkJqsyeASWY2KrjY3NTMvmZmzYGlwE5gSjC/kZl9qfwTmNmIYP0GwBGgECiNsa25wO1mNtTMkomc9lri7lvOdCfcfQMwD3ggOL31NvBbM2thZvXMrJeZXRg0nwn82MyGB/vcOwiHpkTCc0+wX7cTXNwXOREFhNRa7p5B5Pz9o0Qu8GYB3w6WlQJXEbnQmwPkErkAXV4LIkFzgMgppH3Ab2Jsaz7w78ArRIKnF///ukBV+DUw0cw6ELkA3RBYH9T1MpEL47j7S8AviARWPvAnoI27rwd+C3wE7ALOAj6owvqkFjJ9YZCIiMSiHoSIiMSkgBARkZgUECIiEpMCQkREYqrpNzT7J+3atfO0tLR4lyEiUmMsX758r7u3j7WsVgVEWloaGRkZ8S5DRKTGMLOtJ1qmU0wiIhKTAkJERGJSQIiISEwKCBERiUkBISIiMSkgREQkJgWEiIjEVKs+ByEiUpd8nL2PD7P20iS5PpMu/ML3RJ0xBYSISA10pKiEu55dzoGCYto3T1ZAiIhIxOyPtnKgoJjXvnc+w1Jbh7INXYMQEalhDheVMGPhJi7q1z60cAAFhIhIjTP7oy0cKCjmvkv6hrodBYSISA1yuKiEJxZmc3G/9gxNaRXqthQQIiI1yDMfRnoP94bcewAFhIhIjXG4qIQnFmUzun+H0HsPoIAQEakxnvlwCwcLirl3TJ9q2Z4CQkSkBsgvLP5H7+Hsaug9gAJCRKRGmP3RVg4WFHPfJdXTewAFhIhIwssvLGbGwmzG9O/AkG6tqm27CggRkQT3zIdbOHS0mHursfcAIQeEmY01s0/NLMvMfhJjeWsze83MVpvZUjMbXG55kpmtNLM3wqxTRCRRRa49bOaSAdXbe4AQA8LMkoBpwOXAQOAmMxtYrtmDQKa7DwFuAx4ut/xe4JOwahQRSXRPfxD0HsaE/7mH8sLsQYwEstw9292PAc8D48q1GQjMB3D3DUCamXUEMLNuwNeAmSHWKCKSsPIKi5m5eDOXDOjIWd1aVvv2wwyIrsC2qOncYF60VcC1AGY2EugOdAuW/R54ACiraCNmNtHMMswsY8+ePVVQtohIYngm6D1U58ilaGEGhMWY5+WmpwCtzSwTuBtYCZSY2ZXAbndffrKNuPsMd0939/T27dufac0iIgkhL/jcwyUDOjK4a/X3HiDc74PIBVKiprsBO6IbuHsecDuAmRmwOfi5Efi6mV0BNAJamNmz7n5LiPWKiCSMpz/YQl5hSdx6DxBuD2IZ0MfMephZQyJv+q9HNzCzVsEygAnAQnfPc/d/dfdu7p4WrPeuwkFE6oq8wmJmLsrm0oHx6z1AiD0Idy8xs8nAPCAJmOXu68xsUrB8OjAAmG1mpcB64I6w6hERqSmeWhzpPVTXPZdOJNSvHHX3N4E3y82bHvX4I6DCI+DuC4AFIZQnIpJwDh0t5snF2Xw1zr0H0CepRUQSylMfbI70HuJ47eE4BYSISIKI9B42c9mgjgzqEt/eAyggREQSxlMfbCa/sIR74nzt4TgFhIhIAki03gMoIEREEsKsxZHeQzzuuXQiCggRkTg7dLSYWR9sZuygTgzs0iLe5fyDAkJEJM6ePN57SICRS9EUECIicXSooJinFm/m8sGdGNA5cXoPoIAQEYmrJz/YTH5R4oxciqaAEBGJk+O9hyvOSrzeAyggRETi5snF2Qnbe4CQ78UkIlJbrcg5wF9W7Th5wxPIO1rCKytyARj7+0X/mP/zqwdzy7ndz7i+qqCAEBE5RZ9+ns+tM5dQXOYk1z+9EzH5hSUx5z/94RYFhIhITbTvcBF3PLOMpsn1+fPkL9G5ZeN4lxQaBYSISCUVlZQy6dnl7Mkv4oXvnlerwwEUECIileLu/Ntra1m25QCP3DSMoSmt4l1S6DSKSUSkEmYszObl5bncM6YPV53dJd7lVAsFhIjISfx9/S6mvLWBr53VmfsSdEhqGBQQIiIV2PB5Hvc+v5LBXVrym2+eTb16Fu+Sqo0CQkTkBPYeLuKOpzNomlyfJ25Lp3HDpHiXVK10kVpEJIaiklK++8fl7D1cxEuTzqNTy0bxLqnahdqDMLOxZvapmWWZ2U9iLG9tZq+Z2WozW2pmg4P5jYLpVWa2zsz+K8w6RUSiuTv/+uoalm89wG+vP5sh3VrFu6S4CC0gzCwJmAZcDgwEbjKzgeWaPQhkuvsQ4Dbg4WB+ETDa3c8GhgJjzezcsGoVEYn2+MJsXl2xnfsu6cOVQ+rGiKVYwuxBjASy3D3b3Y8BzwPjyrUZCMwHcPcNQJqZdfSIw0GbBsGPh1iriAgA76zfxf++tYErh3Tm3jo0YimWMAOiK7Atajo3mBdtFXAtgJmNBLoD3YLpJDPLBHYD77j7klgbMbOJZpZhZhl79uyp2j0QkTrlk52REUtndY2MWDKrOyOWYgkzIGId2fK9gClA6yAI7gZWAiUA7l7q7kOJBMbI49cnvvCE7jPcPd3d09u3b19VtYtIHbMnv4gJz2TQvFFkxFKjBnVrxFIsYY5iygVSoqa7Af90b1x3zwNuB7BIVG8OfqLbHDSzBcBYYG2I9YpIHVVYXMp3/5jBviNFvPTd8+nYou6NWIolzB7EMqCPmfUws4bAjcDr0Q3MrFWwDGACsNDd88ysvZm1Cto0Bi4BNoRYq4jUUe7Og6+uYUXOQf7v+qGc1a1lvEtKGKH1INy9xMwmA/OAJGCWu68zs0nB8unAAGC2mZUC64E7gtU7A88EI6HqAS+6+xth1Soidddj72/i1ZXb+eGlfbnirM7xLiehhPpBOXd/E3iz3LzpUY8/Ar4wTMDdVwPDwqxNRGTeus/59bxPuersLtw9une8y0k4utWGiNRJ63Yc4gcvZDKka0t+fd2QOj9iKRYFhIjUObvzC7nzmQxaNGqgEUsV0L2YRKROiYxYWs7+gmO8POl8OmjE0gkpIESkznB3fvLKalbmHOSxm89hcFeNWKqITjGJSJ3xhwWb+FPmDn50aV8u14ilk1JAiEid8Nbanfx63qd8/ewuTNaIpUpRQIhIrbd2+yF+8MIqhqa04lcasVRpCggRqdV25xdy5+wMWjVpwIzbhmvE0inQRWoRqbUKi0uZOHs5BwuKeWnSeXRorhFLp0IBISK1krvzwMurydx2kOm3DNeIpdOgU0wiUitNey+L11ft4P7L+jF2cKd4l1MjKSBEpNb525qd/Obtz7h6aBe+d1GveJdTYykgRKRWWbv9ED98cRXDUlsx5RsasXQmFBAiUmvszitkwjMZtG7SgMdv1YilM6WL1CJSKxQWl3Ln7AzyCosj91jSiKUzpoAQkRrP3bn/5dWsyj3E47cOZ2CXFvEuqVbQKSYRqfEeeTeLv6zawQNj+3HZII1YqioKCBGp0d5cs5P/e+czrh3Wlbsu1IilqqSAEJEaa03uIX74YibnpLbif649SyOWqpgCQkRqpF15hUyYvYy2TZN5/FZ9K1wYdJFaRGqco8ciI5byC0t45a7zad88Od4l1Uqh9iDMbKyZfWpmWWb2kxjLW5vZa2a22syWmtngYH6Kmb1nZp+Y2TozuzfMOkWk5oiMWFrFmu2HePjGYQzorBFLYQktIMwsCZgGXA4MBG4ys4Hlmj0IZLr7EOA24OFgfgnwI3cfAJwLfD/GuiJSB02dn8Ubq3fyL2P7c+nAjvEup1YLswcxEshy92x3PwY8D4wr12YgMB/A3TcAaWbW0d13uvuKYH4+8AnQNcRaRaQGeGP1Dn7398+49pyufPcrPeNdTq0XZkB0BbZFTefyxTf5VcC1AGY2EugOdItuYGZpwDBgSayNmNlEM8sws4w9e/ZUTeUiknBW5x7kRy+uIr17a36pEUvVIsyAiPW/5+WmpwCtzSwTuBtYSeT0UuQJzJoBrwD3uXterI24+wx3T3f39Pbt21dJ4SKSWD4/FPlWuHbNkpl+63CS62vEUnUIcxRTLpASNd0N2BHdIHjTvx3AIn8ObA5+MLMGRMJhjru/GmKdIpLAjo9YOlxYwivfO592zTRiqbqE2YNYBvQxsx5m1hC4EXg9uoGZtQqWAUwAFrp7XhAWTwKfuPv/hVijiCSwsjLnxy+tYu2OyIil/p00Yqk6hRYQ7l4CTAbmEbnI/KK7rzOzSWY2KWg2AFhnZhuIjHY6Ppz1S8CtwGgzywx+rgirVhFJTA/P38hf1+zkJ2P7c4lGLFW7UD8o5+5vAm+Wmzc96vFHQJ8Y6y0m9jUMEakj/rJqBw/P38h1w7sxUSOW4kK32hCRhLNq20F+/NIqRqS15hfXDNaIpThRQIhIQtl56Ch3zs6gffNkpt+iEUvxpIAQkYRRcKyEO2dncKSohCe/NYK2GrEUV7pZn4gkhOMjltbtyGPmben069Q83iXVeepBiEhC+P3fP+PNNZ/z4OUDGDNAI5YSgQJCROLuz5nbmfpuFtend2PCBT3iXY4EFBAiElcrcw5w/8urGZnWhp9frXssJZIKr0GYWT5fvH8SRD6j4O6ujzWKyGnbcfAoE/+4nI4tknnslnNoWF9/syaSCgPC3XWVSERCcXzE0tFjpcyZMEojlhLQyXoQbSpa7u77q7YcEakLysqcH76wik925vHkt0bQt6P+Fk1EJxvmupzIKaYT3bpbn38XkVP2u79/xlvrPuenXxvAxf07xLscOYGTnWLScAIRqVJ/ztzOI+9mcUN6Cnd8WW8xiazSH5Qzs9ZEbqzX6Pg8d18YRlEiUjv9Y8RSjzb87GrdYynRVSogzGwCkVtxdwMygXOBj4DRoVUmIrXKjoNHuXP2cjq1aMT0W4ZrxFINUNn/oXuBEcBWd7+YyHdE6wugRaRSCo6VMOGZDIqKS3nyW+m0adrw5CtJ3FU2IArdvRDAzJLdfQPQL7yyRKS2KCtzfvBCJhs+z2Pq+GH00YilGqOy1yByzawV8CfgHTM7QLnvlxYRieW373zKvHW7+I8rB3JxP41YqkkqFRDufk3w8CEzew9oCbwVWlUiUuPtzi9k9odbmfbeJm4amcLtX0qLd0lyiip7kfpcYJ2757v7+2bWnMh1iCWhViciNUpZmfPhpn3MXbqVt9ftoqTMuXxwJ/7r6xqxVBNV9hTTY8A5UdNHYswTkTpq3+EiXl6ey3NLc9iyr4BWTRrw7fPTuGlUKr3aN4t3eXKaKhsQ5u7/uGmfu5eZmb5sSKQOc3c+zt7P3KU5zFv7OcdKyxiR1pr7LunL2MGdaNRAXxVa01X2TT7bzO4h0msA+B6QfbKVzGws8DCQBMx09ynllrcGZgG9gELgO+6+Nlg2C7gS2O3ugytZp4iE7GDBMV5ensvcpTlk7zlC80b1GT8qlfGjUnVPpVqmsgExCZgK/JTIPZjmAxMrWsHMkoBpwKVALrDMzF539/VRzR4EMt39GjPrH7QfEyx7GngUmF3JGkUkJO5OxtYDzF2Sw1/X7ORYSRnDUlvx6+uGcOWQLjRuqN5CbVTZUUy7gRtP8blHAlnung1gZs8D44DogBgI/DLYxgYzSzOzju6+y90XmlnaKW5TRKrQoaPFvLYi0lv4bNdhmiXX54b0FG4amcrALvo6mNqusqOY+hI5vdTR3Qeb2RDg6+7+8wpW6wpsi5rOBUaVa7MKuBZYbGYjge5Ebuexq5L1Y2YTCXozqamplV1NRE7A3cncdpA5S3J4Y/UOCovLGNKtJVOuPYurzu5C02RdfqwrKvs//QRwP/A4gLuvNrO5QEUBcaJbhEebAjxsZpnAGmAlUFLJmghqmQHMAEhPT4/17XciUgn5hcX8KXMHc5fk8MnOPJo0TOKaYd24eVQqg7u2jHd5EgeVDYgm7r603Djmk72R5wIpUdPdKPfpa3fPA24HsMiTbw5+RKSarMk9xNylW/lz5g4KjpUysHMLfn71YMYN7ULzRg3iXZ7EUWUDYq+Z9SLoAZjZdcDOk6yzDOhjZj2A7USuYYyPbhDcvqPA3Y8BE4CFQWiISIiOFJXw+qpIb2HN9kM0alCPq4Z04eZzu3N2t5b6UJsAlQ+I7xM5jdPfzLYT+Sv/5opWcPcSM5sMzCMyzHWWu68zs0nB8unAAGC2mZUSuXh9x/H1zew54CKgnZnlAv/p7k+eys6JyD9bvyOPuUu38qeVOzhcVEK/js35r68P4uphXWnZWL0F+WcW9fm3kzc2a0rkDrBHgRvcfU5YhZ2O9PR0z8jIiHcZIgnl6LFS/rI60lvI3HaQhvXrceVZnRk/KpXh3Vurt1DHmdlyd0+PtazCHoSZtSDSe+gK/Bn4ezD9YyIjkBIqIETk//tsVz5zl+Twyopc8gtL6Nm+Kf9+5UC+cU5XWjXR9zHIyZ3sFNMfgQNEvj3uTuABoCFwtbtnhluaiJyqwuJS/rZ2J3M+ziFj6wEaJtVj7OBOjB+VyqgebdRbkFNysoDo6e5nAZjZTGAvkOru+aFXJiKVlrX7MM8tjfQWDhYUk9a2CQ9e0Z9vnNONts2S412e1FAnC4ji4w/cvdTMNiscRBJDUUkp89btYs7HW1myeT/16xmXDYr0Fs7r2ZZ69dRbkDNzsoA428yODzs1oHEwbYC7uz5rL1LNtuw9wnNLc3hpeS77jxwjpU1jHhjbj28OT6F9c/UWpOpUGBDurjtwiSSA4tIy3lm/i7lLclictZekesYlAzowflR3LujdTr0FCYVuqiKSwLbtL+C5pTm8mJHL3sNFdGnZiB9e2pcbRqTQsUWjeJcntZwCQiTBlJSWMX/DbuYuyWHhxj0YMLp/B8aPSuXCvh1IUm9BqokCQiRBbD94lBeW5vBCxjZ25RXRsUUyd4/uw40jUujSqnG8y5M6SAEhEkelZc6CTyO9hfc+3Y0DX+nTnp+NS2V0/w7UT6oX7xKlDlNAiMTBrrxCXli2jeeX5rDjUCHtmiVz10W9uHFEKiltmsS7PBFAASFSbcrKnEVZe5nz8Vbmb9hNaZnz5d7t+PcrB3LJwI40UG9BEowCQiRke/KLeDFjG88vy2Hb/qO0adqQCRf04KYRqaS1axrv8kROSAEhEoKyMuej7H3MWbKVt9ftoqTMObdnG+6/rD+XDepIcn19xEgSnwJCpArtO1zEy8tzeW5pDlv2FdCqSQO+fX4aN41KpVf7ZvEuT+SUKCBEzpC7s2TzfuYuyeGttZ9zrLSMEWmtufeSPlw+uDONGqi3IDWTAkLkNB0sOPaP3sKmPUdo3qg+40elMn5UKn07No93eSJnTAEhcgrcneVbDzB3SQ5vrNnJsZIyhqW24tfXDeHKIV1o3FC9Bak9FBAilXDoaDGvrcjluaXb+HRXPs2S63N9ejfGj+zOwC66qbHUTgoIkRNwdzK3HWTukhz+snoHhcVlDOnWkinXnsVVZ3ehabJ+faR20ytcpJzSMueN1Tt4/P1s1u/Mo0nDJK4Z1pXxI7tzVreW8S5PpNqEGhBmNhZ4GEgCZrr7lHLLWwOzgF5AIfAdd19bmXVFqlpJaRmvr9rBo+9mkb33CH06NOPnVw9m3NAuNG/UIN7liVS70ALCzJKAacClQC6wzMxed/f1Uc0eBDLd/Roz6x+0H1PJdUWqRHFpGa+t3M6097LYuq+A/p2a89jN53DZoE76Ih6p08LsQYwEstw9G8DMngfGAdFv8gOBXwK4+wYzSzOzjkDPSqwrckaOlZTx6opcpi3IYtv+owzq0oLHbx3OpQM6KhhECDcgugLboqZzgVHl2qwCrgUWm9lIoDvQrZLrAmBmE4GJAKmpqVVSuNRuRSWlvJSRy2MLNrH94FGGdGvJQ1cNYnT/DpgpGESOCzMgYv2mebnpKcDDZpYJrAFWAiWVXDcy030GMAMgPT09ZhsRgMLiUl7M2MZjCzax81Ahw1Jb8YtrBnNh3/YKBpEYwgyIXCAlarobsCO6gbvnAbcDWOQ3dHPw0+Rk64pUVmFxKXOX5DD9/U3szi8ivXtrfnXdEL7cu52CQaQCYQbEMqCPmfUAtgM3AuOjG5hZK6DA3Y8BE4CF7p5nZiddV+RkCo6VMOfjHB5fmM3ew0WM6tGG3984lPN6tlUwiFRCaAHh7iVmNhmYR2So6ix3X2dmk4Ll04EBwGwzKyVyAfqOitYNq1apXY4UlfDHj7fyxMJs9h05xpd6t+XR0cM4t2fbeJcmUqOYe+05bZ+enu4ZGRnxLkPiJL+wmNkfbWXmomwOFBTzlb7tuWd0b9LT2sS7NJGEZWbL3T091jJ9klpqvENHi3nmwy08uXgzh44Wc3G/9twzpg/DUlvHuzSRGk0BITXWwYJjzPpgC099sJn8whIuGdCRe8b0Zki3VvEuTaRWUEBIjXPgyDGeXLyZpz/cwuGiEi4b1JG7R/dhcFfdJ0mkKikgpMbYd7iIJxZt5o8fbaGguJQrBndm8ujeDOis222LhEEBIQlvT34RMxZu4tmPcygsKeWqIV2YPLq3vrVNJGQKCElYu/IKefz9bOYs2UpxaRnjhnbl+xf3pneHZvEuTaROUEBIwtl56CjTF2ziuWXbKC1zrhkWCYYe7ZrGuzSROkUBIQlj+8GjPLYgixeX5VLmzjfO6cb3Lu5F97YKBpF4UEBI3G3bX8AfFmTx8vJcAL6ZnsJdF/YipU2TOFcmUrcpICRutu47wrT3snh1xXbqmXHjiFTuuqgXXVo1jndpIoICQuIge89hHn0viz9n7qB+PeOWc7sz6cJedGrZKN6liUgUBYRUm6zd+TzybhZ/WbWDhvXrcfv5aUz8Sk86tFAwiCQiBYSE7tPP83nk3Y38dc1OGtVP4s4LenLnV3rSrllyvEsTkQooICQ063fk8ci7G/nb2s9p2jCJuy7sxR1f7kFbBYNIjaCAkCq3dvshps7fyNvrd9E8uT53j+7Nd77Ug9ZNG8a7NBE5BQoIqTKZ2w7yyPyNzN+wmxaN6nPfJX24/fwetGzSIN6lichpUEDIGVu+9QBT52/k/c/20KpJA3781b7cdn4aLRopGERqMgWEnLZlW/Yzdf5GFm3cS+smDXhgbD9uOy+NZsl6WYnUBvpNllP20aZ9TJ2/kY+y99G2aUP+9fL+3HJud5oqGERqFf1GS6W4Ox9u2sfD8zeydPN+2jdP5qdfG8DNo7rTuGFSvMsTkRAoIKRC7s7CjXuZOn8jy7ceoGOLZB66aiA3jkylUQMFg0htFmpAmNlY4GEgCZjp7lPKLW8JPAukBrX8xt2fCpbdC9wJGPCEu/8+zFrln7k7Cz7dw8PzN5K57SCdWzbiZ+MG8c30FAWDSB0RWkCYWRIwDbgUyAWWmdnr7r4+qtn3gfXufpWZtQc+NbM5QF8i4TASOAa8ZWZ/dfeNYdUrEe7O3z/ZzdT5G1mz/RBdWzXmf645i28M70pyfQWDSF0SZg9iJJDl7tkAZvY8MA6IDggHmpuZAc2A/UAJMAD42N0LgnXfB64BfhVivXVaWZnz9vrPmTo/i/U780ht04RffWMI15zTlQZJ9eJdnojEQZgB0RXYFjWdC4wq1+ZR4HVgB9AcuMHdy8xsLfALM2sLHAWuADJibcTMJgITAVJTU6t0B+qCsjLnb2s/55F3N7Lh83zS2jbhN988m3FDuygYROq4MAPCYszzctOXAZnAaKAX8I6ZLXL3T8zsf4F3gMPAKiI9iy8+ofsMYAZAenp6+eeXEygtc/66ZiePzN/Ixt2H6dm+Kb+/YShXDulMfQWDiBBuQOQCKVHT3Yj0FKLdDkxxdweyzGwz0B9Y6u5PAk8CmNn/BM8nZ6iktIy/rN7BI+9mkb3nCH06NGPqTcP42lmdSaoXK9NFpK4KMyCWAX3MrAewHbgRGF+uTQ4wBlhkZh2BfsDxaxYd3H23maUC1wLnhVhrrVdcWsafVm5n2ntZbNlXQP9OzfnDzecwdlAn6ikYRCSG0ALC3UvMbDIwj8gw11nuvs7MJgXLpwM/A542szVETkn9i7vvDZ7ileAaRDHwfXc/EFattdmxkjJeW5nLtPc2kbO/gIGdWzD9luF8dWBHBYOIVMgiZ3dqh/T0dM/IiHktu84pKinl5eW5/OG9TWw/eJQh3Vpyz+g+jBnQgcigMRERMLPl7p4ea5k+SV3LFBaX8mLGNh5bsImdhwoZmtKKn189mIv6tVcwiMgpUUDUEoXFpTy3NIfp729iV14Rw7u35n+/MYQL+rRTMIjIaVFA1HBHj5UyZ8lWpr+fzd7DRYzs0YbfXT+U83q1VTCIyBlRQNRQR4pKePbjrTyxKJu9h49xfq+2PDp+GOf2bBvv0kSkllBA1DD5hcXM/mgrMxdlc6CgmAv6tOOeMX0YkdYm3qWJSC2jgKgh8gqLeeaDLcxcvJlDR4u5qF977h7dh+HdW8e7NBGppRQQCe5QQTGzPtjMrA82k19YwiUDOnD36D6cndIq3qWJSC2ngEhQB44cY9YHm3n6gy3kF5Xw1YEduWdMHwZ3bRnv0kSkjlBAJJh9h4uYuXgzsz/cwpFjpVxxVicmX9yHgV1axLs0EaljFBAJYk9+EU8syuaPH22lsKSUK4d0YfLFvenXqXm8SxOROkoBEWe78wp5fGE2c5Zs5VhJGV8/uwuTR/emdwcFg4jElwIiTnYeOsrj72czd2kOpWXO1UO78v2Le9GzfbN4lyYiAiggqt32g0d5bEEWLy7Lpcyda8/pyvcu6k1au6bxLk1E5J8oIKrJtv0F/GHBJl5eHvkW1uuGp/C9i3qR0qZJnCsTEYlNARGyrfuOMO29LF5dsZ16ZtwwIoW7LupN11aN412aiEiFFBAhyd5zmGnvbeJPmdtJqmfccm53vnthTzq3VDCISM2ggKhiWbvzefTdLF5ftYMGSfX41nlpTLqwJx1aNIp3aSIip0QBUUU+25XPI+9m8cbqHTSqn8SEC3oy4YIedGiuYBCRmkkBcYY+2ZnHI+9u5M01n9O0YRKTLuzFhC/3oG2z5HiXJiJyRhQQp2nt9kM88u5G5q3bRbPk+ky+uDd3fLkHrZs2jHdpIiJVQgFxilZtO8gj727k75/spnmj+tw7pg/f+VIPWjZpEO/SRESqVKgBYWZjgYeBJGCmu08pt7wl8CyQGtTyG3d/Klj2A2AC4MAa4HZ3Lwyz3oqsyDnA1PkbWfDpHlo2bsAPL+3Lt85Po2VjBYOI1E6hBYSZJQHTgEuBXGCZmb3u7uujmn0fWO/uV5lZe+BTM5sDtAfuAQa6+1EzexG4EXg6rHpPJGPLfh6ev5FFG/fSukkD7r+sH7ed153mjRQMIlK7hdmDGAlkuXs2gJk9D4wDogPCgeZmZkAzYD9QElVbYzMrBpoAO0Ks9Qs+zt7H1Pkb+XDTPto2bchPLu/Pred2p2myzsqJSN0Q5rtdV2Bb1HQuMKpcm0eB14m8+TcHbnD3MmC7mf0GyAGOAm+7+9uxNmJmE4GJAKmpqWdUsLvz0aZ9/H7+RpZu3k+7Zsn89GsDGD8qlSYNFQwiUreE+a5nMeZ5uenLgExgNNALeMfMFhG5ZjEO6AEcBF4ys1vc/dkvPKH7DGAGQHp6evnnrxR3Z9HGvUydv5GMrQfo2CKZ/7xqIDeNTKVRg6TTeUoRkRovzIDIBVKiprvxxdNEtwNT3N2BLDPbDPQHugOb3X0PgJm9CpxP5IJ2lcorLOZbs5ayMucgnVs24r/HDeL69BQFg4jUeWEGxDKgj5n1ALYTucg8vlybHGAMsMjMOgL9gGwivY9zzawJkVNMY4CMMIpsnlyf7m2acN3wblw3vBvJ9RUMIiIQYkC4e4mZTQbmETllNMvd15nZpGD5dOBnwNNmtoZIKPyLu+8F9prZy8AKIhetVxKcRqpqZsbvbxwWxlOLiNRoFjm7Uzukp6d7RkYoHQ0RkVrJzJa7e3qsZfWquxgREakZFBAiIhKTAkJERGJSQIiISEwKCBERiUkBISIiMSkgREQkplr1OQgz2wNsBdoBe+NcTiLScTkxHZvYdFxiq03Hpbu7t4+1oFYFxHFmlnGiD37UZTouJ6ZjE5uOS2x15bjoFJOIiMSkgBARkZhqa0CEcmO/WkDH5cR0bGLTcYmtThyXWnkNQkREzlxt7UGIiMgZUkCIiEhMCR8QZjbWzD41sywz+0mM5WZmU4Plq83snJOta2Y/C9pmmtnbZtaluvanKoVxbKKW/9jM3Mzahb0fVS2k18xDZrY9eM1kmtkV1bU/VSWs14uZ3R0sW2dmv6qOfalKIb1eXoh6rWwxs8xq2p2q5e4J+0Pkm+g2AT2BhsAqYGC5NlcAfyP4mlJgycnWBVpErX8PMD3e+5ooxyZYnkLkmwC3Au3iva+JcFyAh4Afx3v/EvC4XAz8HUgOpjvEe18T4biUW/+3wH/Ee19P5yfRexAjgSx3z3b3Y8DzwLhybcYBsz3iY6CVmXWuaF13z4tavylQE6/Uh3JsAr8DHkDHJda6NVVYx+UuYIq7FwG4++7q2JkqFOrrxcwMuB54LuwdCUOiB0RXYFvUdG4wrzJtKlzXzH5hZtuAm4H/qMKaq0sox8bMvg5sd/dVVV1wNQntNQNMDk4xzDKz1lVXcrUI67j0BS4wsyVm9r6ZjajSqsMX5usF4AJgl7tvrJJqq1miB4TFmFf+r9oTtalwXXf/N3dPAeYAk0+7wvip8mNjZk2Af6NmBuZxYb1mHgN6AUOBnUROG9QkYR2X+kBrIqde7gdeDP5qrilCe48J3EQN7T1A4gdELpHz4cd1A3ZUsk1l1gWYC3zjjCutfmEcm15AD2CVmW0J5q8ws05VWnm4QnnNuPsudy919zLgCSKnF2qSsH6XcoFXg9MvS4EyIjeyqylCe48xs/rAtcALVVhv9Yr3RZCKfoj8dZJN5E3r+EWgQeXafI1/voC09GTrAn2i1r8beDne+5oox6bc+luoeRepw3rNdI5a/wfA8/He1wQ5LpOA/w4e9yVyysXivb/xPi7B8rHA+/HexzM6PvEuoBL/gVcAnxEZLfBvwbxJwKTgsQHTguVrgPSK1g3mvwKsBVYDfwG6xns/E+XYlHv+GhcQIb5m/hi0XQ28Hh0YNeUnpOPSEHg2+H1aAYyO934mwnEJlj19/Dlq6o9utSEiIjEl+jUIERGJEwWEiIjEpIAQEZGYFBAiIhKTAkJERGJSQIiUY2alwV0415rZS8EnzM/0Of/bzC6pYPkkM7vtTLcjUpU0zFWkHDM77O7NgsdzgOXu/n9Ry5PcvTRuBYpUE/UgRCq2COhtZheZ2XtmNhdYY2ZJZvZrM1sW3MDvu8dXMLMHzGyNma0ysynBvKfN7Lrg8RQzWx+s95tg3kNm9uPg8VAz+zhY/trxGwOa2QIz+18zW2pmn5nZBdV9MKRuqR/vAkQSVXAvncuBt4JZI4HB7r7ZzCYCh9x9hJklAx+Y2dtAf+BqYJS7F5hZm3LP2Qa4Bujv7m5mrWJsejZwt7u/b2b/DfwncF+wrL67jwy+sOg/gROethI5U+pBiHxR4+AbwDKAHODJYP5Sd98cPP4qcFvQbgnQFuhD5A37KXcvAHD3/eWeOw8oBGaa2bVAQfRCM2sJtHL394NZzwBfiWryavDvciDt9HdR5OTUgxD5oqPuPjR6RnAH6yPRs4j8lT+vXLuxVPBFS+5eYmYjgTHAjURuNT/6FGorCv4tRb+/EjL1IEROzzzgLjNrAGBmfc2sKfA28J3jI59inGJqBrR09zeJnDYaGr3c3Q8BB6KuL9wKvI9IHOgvEJHTM5PIKZ4VwRfk7AGudve3zGwokGFmx4A3gQej1msO/NnMGhHphfwgxnN/C5gehEw2cHtoeyFSAQ1zFRGRmHSKSUREYlJAiIhITAoIERGJSQEhIiIxKSBERCQmBYSIiMSkgBARkZj+H7khBq9fmDIZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Precision and Recall curve for different values of C\n",
    "plt.plot(res['Precision'],res['Recall'])\n",
    "plt.title('Precision Recall')\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 2: RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = np.linspace(70,120,10).astype('int64')\n",
    "depth = np.linspace(2,8,4).astype('int64')\n",
    "param = {'n_estimators':est,'max_depth':depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.9799230805405463\n",
      "Best Parameters: {'n_estimators': 97, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "clf = RandomizedSearchCV(model, param,cv = 5, scoring = 'roc_auc')\n",
    "\n",
    "clf.fit(X_train_scl,y_train)\n",
    "\n",
    "print(\"Best Score:\" + str(clf.best_score_))\n",
    "print(\"Best Parameters: \" + str(clf.best_params_))\n",
    "best_est = clf.best_params_['n_estimators']\n",
    "best_depth = clf.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected model with best ROC AUC score having 'max_depth':8, 'n_estiamtors': '83'\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = best_est,max_depth = best_depth,class_weight='balanced')\n",
    "model.fit(X_train_scl,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for the model: 0.007651666970304245\n",
      "Recall score for the model: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "print('Precision Score for the model:', precision_score(y_test,y_pred))\n",
    "print('Recall score for the model:',recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x240a2ed6400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model,X_test_scl, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to solve for the low Precision score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    749566\n",
       "1       434\n",
       "Name: isFraud, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clus = df[df.isFraud == 1].isFraud.sum()\n",
    "n_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(749566, 73)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonFraud = df[df.isFraud == 0]\n",
    "nonFraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>type_CASH_IN</th>\n",
       "      <th>type_CASH_OUT</th>\n",
       "      <th>type_DEBIT</th>\n",
       "      <th>type_PAYMENT</th>\n",
       "      <th>type_TRANSFER</th>\n",
       "      <th>isFlaggedFraud_0</th>\n",
       "      <th>isFlaggedFraud_1</th>\n",
       "      <th>CustTypeOrig_Customer</th>\n",
       "      <th>CustTypeDest_Customer</th>\n",
       "      <th>CustTypeDest_Merchant</th>\n",
       "      <th>Day_1.0</th>\n",
       "      <th>Day_10.0</th>\n",
       "      <th>Day_11.0</th>\n",
       "      <th>Day_12.0</th>\n",
       "      <th>Day_13.0</th>\n",
       "      <th>Day_14.0</th>\n",
       "      <th>Day_15.0</th>\n",
       "      <th>Day_16.0</th>\n",
       "      <th>Day_17.0</th>\n",
       "      <th>Day_18.0</th>\n",
       "      <th>Day_19.0</th>\n",
       "      <th>Day_2.0</th>\n",
       "      <th>Day_20.0</th>\n",
       "      <th>Day_21.0</th>\n",
       "      <th>Day_22.0</th>\n",
       "      <th>Day_23.0</th>\n",
       "      <th>Day_24.0</th>\n",
       "      <th>Day_25.0</th>\n",
       "      <th>Day_26.0</th>\n",
       "      <th>Day_27.0</th>\n",
       "      <th>Day_28.0</th>\n",
       "      <th>Day_29.0</th>\n",
       "      <th>Day_3.0</th>\n",
       "      <th>Day_30.0</th>\n",
       "      <th>Day_31.0</th>\n",
       "      <th>Day_32.0</th>\n",
       "      <th>Day_4.0</th>\n",
       "      <th>Day_5.0</th>\n",
       "      <th>Day_6.0</th>\n",
       "      <th>Day_7.0</th>\n",
       "      <th>Day_8.0</th>\n",
       "      <th>Day_9.0</th>\n",
       "      <th>Hour_0</th>\n",
       "      <th>Hour_1</th>\n",
       "      <th>Hour_2</th>\n",
       "      <th>Hour_3</th>\n",
       "      <th>Hour_4</th>\n",
       "      <th>Hour_5</th>\n",
       "      <th>Hour_6</th>\n",
       "      <th>Hour_7</th>\n",
       "      <th>Hour_8</th>\n",
       "      <th>Hour_9</th>\n",
       "      <th>Hour_10</th>\n",
       "      <th>Hour_11</th>\n",
       "      <th>Hour_12</th>\n",
       "      <th>Hour_13</th>\n",
       "      <th>Hour_14</th>\n",
       "      <th>Hour_15</th>\n",
       "      <th>Hour_16</th>\n",
       "      <th>Hour_17</th>\n",
       "      <th>Hour_18</th>\n",
       "      <th>Hour_19</th>\n",
       "      <th>Hour_20</th>\n",
       "      <th>Hour_21</th>\n",
       "      <th>Hour_22</th>\n",
       "      <th>Hour_23</th>\n",
       "      <th>transferAmntCheck_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  newbalanceDest  \\\n",
       "0  9839.64       170136.0       160296.36             0.0             0.0   \n",
       "1  1864.28        21249.0        19384.72             0.0             0.0   \n",
       "\n",
       "   type_CASH_IN  type_CASH_OUT  type_DEBIT  type_PAYMENT  type_TRANSFER  \\\n",
       "0             0              0           0             1              0   \n",
       "1             0              0           0             1              0   \n",
       "\n",
       "   isFlaggedFraud_0  isFlaggedFraud_1  CustTypeOrig_Customer  \\\n",
       "0                 1                 0                      1   \n",
       "1                 1                 0                      1   \n",
       "\n",
       "   CustTypeDest_Customer  CustTypeDest_Merchant  Day_1.0  Day_10.0  Day_11.0  \\\n",
       "0                      0                      1        1         0         0   \n",
       "1                      0                      1        1         0         0   \n",
       "\n",
       "   Day_12.0  Day_13.0  Day_14.0  Day_15.0  Day_16.0  Day_17.0  Day_18.0  \\\n",
       "0         0         0         0         0         0         0         0   \n",
       "1         0         0         0         0         0         0         0   \n",
       "\n",
       "   Day_19.0  Day_2.0  Day_20.0  Day_21.0  Day_22.0  Day_23.0  Day_24.0  \\\n",
       "0         0        0         0         0         0         0         0   \n",
       "1         0        0         0         0         0         0         0   \n",
       "\n",
       "   Day_25.0  Day_26.0  Day_27.0  Day_28.0  Day_29.0  Day_3.0  Day_30.0  \\\n",
       "0         0         0         0         0         0        0         0   \n",
       "1         0         0         0         0         0        0         0   \n",
       "\n",
       "   Day_31.0  Day_32.0  Day_4.0  Day_5.0  Day_6.0  Day_7.0  Day_8.0  Day_9.0  \\\n",
       "0         0         0        0        0        0        0        0        0   \n",
       "1         0         0        0        0        0        0        0        0   \n",
       "\n",
       "   Hour_0  Hour_1  Hour_2  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  \\\n",
       "0       0       1       0       0       0       0       0       0       0   \n",
       "1       0       1       0       0       0       0       0       0       0   \n",
       "\n",
       "   Hour_9  Hour_10  Hour_11  Hour_12  Hour_13  Hour_14  Hour_15  Hour_16  \\\n",
       "0       0        0        0        0        0        0        0        0   \n",
       "1       0        0        0        0        0        0        0        0   \n",
       "\n",
       "   Hour_17  Hour_18  Hour_19  Hour_20  Hour_21  Hour_22  Hour_23  \\\n",
       "0        0        0        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0   \n",
       "\n",
       "   transferAmntCheck_1  \n",
       "0                    1  \n",
       "1                    1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nonFraud = nonFraud.drop(['isFraud'], axis = 1)\n",
    "X_nonFraud.head(2)\n",
    "\n",
    "#X_nonFraud_scl = StandardScaler().fit_transform(X_nonFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=434, random_state=42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = KMeans(n_clusters = n_clus, random_state = 42)\n",
    "cluster.fit(nonFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(434, 73)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids = cluster.cluster_centers_\n",
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31748369e+04, 7.99034468e+03, 4.43988091e+03, 1.63932507e+03,\n",
       "       1.73341177e+03, 0.00000000e+00, 1.45893769e-02, 5.03163859e-02,\n",
       "       4.00359645e-03, 9.27115318e-01, 3.97532246e-03, 1.00000000e+00,\n",
       "       0.00000000e+00, 1.00000000e+00, 7.28846817e-02, 9.27115318e-01,\n",
       "       2.14254613e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.22292907e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.34524799e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       7.13069933e-03, 9.51136897e-03, 3.19496044e-03, 1.40238972e-03,\n",
       "       1.35715134e-03, 1.76429674e-03, 4.50121861e-03, 1.61727201e-02,\n",
       "       3.49523018e-02, 8.39963583e-02, 8.63035156e-02, 8.71743544e-02,\n",
       "       9.98524098e-02, 8.97472871e-02, 7.19346758e-02, 5.09214492e-02,\n",
       "       5.23125293e-02, 5.03163859e-02, 5.92566204e-02, 5.96807301e-02,\n",
       "       5.60390407e-02, 3.31031831e-02, 2.47453928e-02, 1.46289605e-02,\n",
       "       1.00000000e+00])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>type_CASH_IN</th>\n",
       "      <th>type_CASH_OUT</th>\n",
       "      <th>type_DEBIT</th>\n",
       "      <th>type_PAYMENT</th>\n",
       "      <th>type_TRANSFER</th>\n",
       "      <th>isFlaggedFraud_0</th>\n",
       "      <th>isFlaggedFraud_1</th>\n",
       "      <th>CustTypeOrig_Customer</th>\n",
       "      <th>CustTypeDest_Customer</th>\n",
       "      <th>CustTypeDest_Merchant</th>\n",
       "      <th>Day_1.0</th>\n",
       "      <th>Day_10.0</th>\n",
       "      <th>Day_11.0</th>\n",
       "      <th>Day_12.0</th>\n",
       "      <th>Day_13.0</th>\n",
       "      <th>Day_14.0</th>\n",
       "      <th>Day_15.0</th>\n",
       "      <th>Day_16.0</th>\n",
       "      <th>Day_17.0</th>\n",
       "      <th>Day_18.0</th>\n",
       "      <th>Day_19.0</th>\n",
       "      <th>Day_2.0</th>\n",
       "      <th>Day_20.0</th>\n",
       "      <th>Day_21.0</th>\n",
       "      <th>Day_22.0</th>\n",
       "      <th>Day_23.0</th>\n",
       "      <th>Day_24.0</th>\n",
       "      <th>Day_25.0</th>\n",
       "      <th>Day_26.0</th>\n",
       "      <th>Day_27.0</th>\n",
       "      <th>Day_28.0</th>\n",
       "      <th>Day_29.0</th>\n",
       "      <th>Day_3.0</th>\n",
       "      <th>Day_30.0</th>\n",
       "      <th>Day_31.0</th>\n",
       "      <th>Day_32.0</th>\n",
       "      <th>Day_4.0</th>\n",
       "      <th>Day_5.0</th>\n",
       "      <th>Day_6.0</th>\n",
       "      <th>Day_7.0</th>\n",
       "      <th>Day_8.0</th>\n",
       "      <th>Day_9.0</th>\n",
       "      <th>Hour_0</th>\n",
       "      <th>Hour_1</th>\n",
       "      <th>Hour_2</th>\n",
       "      <th>Hour_3</th>\n",
       "      <th>Hour_4</th>\n",
       "      <th>Hour_5</th>\n",
       "      <th>Hour_6</th>\n",
       "      <th>Hour_7</th>\n",
       "      <th>Hour_8</th>\n",
       "      <th>Hour_9</th>\n",
       "      <th>Hour_10</th>\n",
       "      <th>Hour_11</th>\n",
       "      <th>Hour_12</th>\n",
       "      <th>Hour_13</th>\n",
       "      <th>Hour_14</th>\n",
       "      <th>Hour_15</th>\n",
       "      <th>Hour_16</th>\n",
       "      <th>Hour_17</th>\n",
       "      <th>Hour_18</th>\n",
       "      <th>Hour_19</th>\n",
       "      <th>Hour_20</th>\n",
       "      <th>Hour_21</th>\n",
       "      <th>Hour_22</th>\n",
       "      <th>Hour_23</th>\n",
       "      <th>transferAmntCheck_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13174.836931</td>\n",
       "      <td>7.990345e+03</td>\n",
       "      <td>4.439881e+03</td>\n",
       "      <td>1.639325e+03</td>\n",
       "      <td>1.733412e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014589</td>\n",
       "      <td>5.031639e-02</td>\n",
       "      <td>4.003596e-03</td>\n",
       "      <td>9.271153e-01</td>\n",
       "      <td>3.975322e-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072885</td>\n",
       "      <td>9.271153e-01</td>\n",
       "      <td>0.214255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007131</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>1.402390e-03</td>\n",
       "      <td>1.357151e-03</td>\n",
       "      <td>1.764297e-03</td>\n",
       "      <td>4.501219e-03</td>\n",
       "      <td>1.617272e-02</td>\n",
       "      <td>0.034952</td>\n",
       "      <td>0.083996</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>0.087174</td>\n",
       "      <td>0.099852</td>\n",
       "      <td>0.089747</td>\n",
       "      <td>0.071935</td>\n",
       "      <td>0.050921</td>\n",
       "      <td>0.052313</td>\n",
       "      <td>0.050316</td>\n",
       "      <td>0.059257</td>\n",
       "      <td>0.059681</td>\n",
       "      <td>0.056039</td>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180717.432672</td>\n",
       "      <td>8.803422e+06</td>\n",
       "      <td>8.984140e+06</td>\n",
       "      <td>3.937360e+06</td>\n",
       "      <td>3.901684e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.775558e-16</td>\n",
       "      <td>-1.734723e-18</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>2.775558e-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.551115e-17</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>-2.168404e-19</td>\n",
       "      <td>4.336809e-19</td>\n",
       "      <td>-1.084202e-19</td>\n",
       "      <td>-1.301043e-18</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.090517</td>\n",
       "      <td>0.081897</td>\n",
       "      <td>0.107759</td>\n",
       "      <td>0.116379</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.107759</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0   13174.836931   7.990345e+03    4.439881e+03    1.639325e+03   \n",
       "1  180717.432672   8.803422e+06    8.984140e+06    3.937360e+06   \n",
       "\n",
       "   newbalanceDest  isFraud  type_CASH_IN  type_CASH_OUT    type_DEBIT  \\\n",
       "0    1.733412e+03      0.0      0.014589   5.031639e-02  4.003596e-03   \n",
       "1    3.901684e+06      0.0      1.000000  -2.775558e-16 -1.734723e-18   \n",
       "\n",
       "   type_PAYMENT  type_TRANSFER  isFlaggedFraud_0  isFlaggedFraud_1  \\\n",
       "0  9.271153e-01   3.975322e-03               1.0               0.0   \n",
       "1 -5.551115e-17   2.775558e-17               1.0               0.0   \n",
       "\n",
       "   CustTypeOrig_Customer  CustTypeDest_Customer  CustTypeDest_Merchant  \\\n",
       "0                    1.0               0.072885           9.271153e-01   \n",
       "1                    1.0               1.000000          -5.551115e-17   \n",
       "\n",
       "    Day_1.0  Day_10.0  Day_11.0  Day_12.0  Day_13.0  Day_14.0  Day_15.0  \\\n",
       "0  0.214255       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1  0.155172       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   Day_16.0  Day_17.0  Day_18.0  Day_19.0   Day_2.0  Day_20.0  Day_21.0  \\\n",
       "0       0.0       0.0       0.0       0.0  0.722293       0.0       0.0   \n",
       "1       0.0       0.0       0.0       0.0  0.797414       0.0       0.0   \n",
       "\n",
       "   Day_22.0  Day_23.0  Day_24.0  Day_25.0  Day_26.0  Day_27.0  Day_28.0  \\\n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   Day_29.0   Day_3.0  Day_30.0  Day_31.0  Day_32.0  Day_4.0  Day_5.0  \\\n",
       "0       0.0  0.063452       0.0       0.0       0.0      0.0      0.0   \n",
       "1       0.0  0.047414       0.0       0.0       0.0      0.0      0.0   \n",
       "\n",
       "   Day_6.0  Day_7.0  Day_8.0  Day_9.0    Hour_0    Hour_1    Hour_2  \\\n",
       "0      0.0      0.0      0.0      0.0  0.007131  0.009511  0.003195   \n",
       "1      0.0      0.0      0.0      0.0  0.004310  0.004310  0.008621   \n",
       "\n",
       "         Hour_3        Hour_4        Hour_5        Hour_6        Hour_7  \\\n",
       "0  1.402390e-03  1.357151e-03  1.764297e-03  4.501219e-03  1.617272e-02   \n",
       "1 -2.168404e-19  4.336809e-19 -1.084202e-19 -1.301043e-18  3.469447e-18   \n",
       "\n",
       "     Hour_8    Hour_9   Hour_10   Hour_11   Hour_12   Hour_13   Hour_14  \\\n",
       "0  0.034952  0.083996  0.086304  0.087174  0.099852  0.089747  0.071935   \n",
       "1  0.004310  0.090517  0.081897  0.107759  0.116379  0.094828  0.107759   \n",
       "\n",
       "    Hour_15   Hour_16   Hour_17   Hour_18   Hour_19   Hour_20   Hour_21  \\\n",
       "0  0.050921  0.052313  0.050316  0.059257  0.059681  0.056039  0.033103   \n",
       "1  0.077586  0.086207  0.051724  0.043103  0.038793  0.051724  0.017241   \n",
       "\n",
       "    Hour_22   Hour_23  transferAmntCheck_1  \n",
       "0  0.024745  0.014629                  1.0  \n",
       "1  0.004310  0.008621                  1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids_df = pd.DataFrame(centroids,columns = df.columns)\n",
    "centroids_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(868, 73)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDf = pd.concat([centroids_df,df[df['isFraud']==1]])\n",
    "newDf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = newDf.drop(['isFraud'],axis = 1)\n",
    "ynew = newDf.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(Xnew,ynew, test_size = .25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of training data: (651, 72) (651,)\n",
      "Shapes of test data: (217, 72) (217,)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes of training data:',X_train_new.shape,y_train_new.shape)\n",
    "print('Shapes of test data:',X_test_new.shape,y_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StandardScaler()\n",
    "X_train_scl_new = s.fit_transform(X_train_new)\n",
    "X_test_scl_new = s.transform(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.9957489689797384\n",
      "Best Parameters: {'C': 46.41588833612773}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "c = np.logspace(-3,3,10)\n",
    "param = {'C':c}\n",
    "#penalize = ['l1','l2']\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "clf  = GridSearchCV(model,param, cv = 5,scoring = 'roc_auc')\n",
    "\n",
    "clf.fit(X_train_scl_new,y_train_new)\n",
    "\n",
    "print(\"Best Score:\" + str(clf.best_score_))\n",
    "print(\"Best Parameters: \" + str(clf.best_params_))\n",
    "best_c = clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=best_c,class_weight = 'balanced')\n",
    "model.fit(X_train_scl_new,y_train_new)\n",
    "\n",
    "y_pred_new = model.predict(X_test_scl_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for the model: 0.9818181818181818\n",
      "Recall score for the model: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Precision Score for the model:', precision_score(y_test_new,y_pred_new))\n",
    "print('Recall score for the model:',recall_score(y_test_new,y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x240a85527f0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model,X_test_scl_new, y_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "est = np.linspace(70,120,10).astype('int64')\n",
    "depth = np.linspace(2,8,4).astype('int64')\n",
    "param = {'n_estimators':est,'max_depth':depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:1.0\n",
      "Best Parameters: {'n_estimators': 103, 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "clf = RandomizedSearchCV(model, param,cv = 5, scoring = 'roc_auc')\n",
    "\n",
    "clf.fit(X_train_scl_new,y_train_new)\n",
    "\n",
    "print(\"Best Score:\" + str(clf.best_score_))\n",
    "print(\"Best Parameters: \" + str(clf.best_params_))\n",
    "best_est = clf.best_params_['n_estimators']\n",
    "best_depth = clf.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score for the model: 1.0\n",
      "Recall score for the model: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand = RandomForestClassifier(n_estimators = best_est,max_depth = best_depth,class_weight='balanced')\n",
    "rand.fit(X_train_scl_new,y_train_new)\n",
    "\n",
    "y_pred_new = rand.predict(X_test_scl_new)\n",
    "\n",
    "print('Precision Score for the model:', precision_score(y_test_new,y_pred_new))\n",
    "print('Recall score for the model:',recall_score(y_test_new,y_pred_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109,   0],\n",
       "       [  0, 108]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_new, y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x240ab782b20>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(rand,X_test_scl_new, y_test_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
